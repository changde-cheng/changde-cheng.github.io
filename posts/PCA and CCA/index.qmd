---
title: "What is canonical correlation analysis"
author: "Changde Cheng"
date: "2022-10-18"
---

Canonical correlation provides a characterization of relations between two systems. Canonical correlation analysis works by identifying corresponding pairs of components that are highly correlated across systems. 

Here is an example. Suppose we have RNA-seq results for a sample of patients, and we also measured their methylation profiles, say by EPIC-850k array. We want to know the relation between gene expression and methylation, which is very complicated given 50,000 genes and 800,000 probes. Canonical correlation analysis can be helpful to give us executive summary on the relation by reducing hundreds of thousands of genes and probes to a handful component pairs.

### What is Canonical Correlation?

Given two random vectors $\mathbf x$ and $\mathbf y$:

$$\mathbf{x} = 
\begin{pmatrix}
x_1 \\
x_2 \\
\cdots \\
x_p
\end{pmatrix}, \qquad
\mathbf{y} = 
\begin{pmatrix}
y_1 \\
y_2 \\
\cdots \\
y_q
\end{pmatrix}$$

Canonical variables are a pair of corresponding vectors $\mathbf{a} \in R_p$ and $\mathbf{b} \in R_q$ which maximize the correlation:
$$\mathrm{cor}(\mathbf{a_1^T x},\mathbf{b_1^T y}) = \max_{\substack{\mathrm{var}(\mathbf{a^T x})=1 \\ \mathrm{var}(\mathbf{b^T y})=1}}{\mathrm{cor}(\mathbf{a^T x},\mathbf{b^T y})},
$${#eq-eq1}
where $\mathbf{a_1^T x}$ and $\mathbf{b_1^T y}$ are called the first pair of canonical variables. There can be more canonical variables out there that are not correlated with each other. 

#### Canonical variables from eigenvectors

Consider the covariance matrix $V$ of the stacked random vector $\pmatrix{\mathbf{x}\\ \mathbf{y}}$:
$$V = 
\begin{pmatrix}
\mathrm{var}(\mathbf{x}) & \mathrm{cov}(\mathbf{x},\mathbf{y})\\
\mathrm{cov}(\mathbf{y},\mathbf{x}) & \mathrm{var}(\mathbf{y})
\end{pmatrix}=
\begin{pmatrix}
V_{xx} & V_{xy}\\
V_{yx} & V_{yy}
\end{pmatrix}$${#eq-eq2}

The correlation to maximize in @{eq-eq1} is
$$\mathrm{cor}(\mathbf{a^T x},\mathbf{b^T y})=\frac{ \mathrm{cov}({\mathbf{a^T x},\mathbf{b^T y})} }{ \mathrm{var}(\mathbf{a^T x})^{\frac{1}{2}}~\mathrm{var}(\mathbf{b^T y})^{\frac{1}{2}} } = \mathrm{cov}({\mathbf{a^T x},\mathbf{b^T y})}=\mathbf{a^T} V_{xy} \mathbf{b},$$
as the variances of $\mathbf{a^T x}$ and $\mathbf{b^T y}$ are 1.

By the method of Lagrange multipliers, we set up a function:
$$\begin{align}
G &= \mathrm{cov}(\mathbf{a^T x},\mathbf{b^T y}) - \lambda_1 \left\{ \mathrm{var}(\mathbf{a^T x})-1 \right\} -  \lambda_2 \left\{ \mathrm{var}(\mathbf{b^T y})-1 \right\} \\
&= \mathbf{a^T} V_{xy} \mathbf{b} - \lambda_1 \left\{ \mathbf{a^T} V_{xx} \mathbf{a} -1 \right\} -  \lambda_2 \left\{ \mathbf{b^T} V_{yy} \mathbf{b} -1\right\}
\end{align}
$$

Let 
$$\frac{\partial G}{\partial \mathbf{a}} = 0,\qquad \frac{\partial G}{\partial \mathbf{b}} = 0,$$
from which we reach a systems of linear equations: 
$$\begin{cases}
V_{xy} \mathbf{b} - 2\lambda_1 V_{xx} \mathbf{a} &= 0,\\
V_{yx} \mathbf{a} - 2\lambda_2 V_{yy} \mathbf{b} &= 0.
\end{cases}$${#eq-eq3}

From @{eq-eq3}, we get:

$$\begin{cases}
\lambda_1  = \lambda_1 \mathbf{a^T} V_{xx} \mathbf{a} =\frac{1}{2} \mathbf{a^T} V_{xy} \mathbf{b},\\
\lambda_2  = \lambda_2 \mathbf{b^T} V_{yy} \mathbf{b} =\frac{1}{2} \mathbf{b^T} V_{yx} \mathbf{a} = \lambda_1^{\mathrm T} = \lambda_1.
\end{cases}$${#eq-eq4}

Therefore, @{eq-eq3} becomes:
$$\begin{cases}
V_{xy} \mathbf{b} - 2\lambda V_{xx} \mathbf{a} &= 0,\\
V_{yx} \mathbf{a} - 2\lambda V_{yy} \mathbf{b} &= 0.
\end{cases}$${#eq-eq5}

Solve $\mathbf{a}$ from the first equation in @{eq-eq5} and substitute into the second equation in @{eq-eq5}. When $\lambda \ne 0$, we have:
$$V_{yy}^{-1} V_{yx} V_{xx}^{-1} V_{xy} \mathbf{b} =  4\lambda^2 \mathbf{b} $$
Therefor, $\mathbf{b}$ is an eigenvector of $V_{yy}^{-1} V_{yx} V_{xx}^{-1} V_{xy}$ and $4\lambda^2$ its corresponding eigenvalue. Similarly, $\mathbf{a}$ is an eigenvector of $V_{xx}^{-1} V_{xy} V_{yy}^{-1} V_{yx}$ and $4\lambda^2$ its corresponding eigenvalue.



